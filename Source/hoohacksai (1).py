# -*- coding: utf-8 -*-
"""HooHacksAI.ipynb

Automatically generated by Colaboratory.

"""

#Connect google drive
from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#Replace with path to the dataset
dataset_path = '/content/drive/MyDrive/Data'

# Set the image size and batch size
img_size = (224, 224)
batch_size = 16

# Create data generators for training and validation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Model architecture
model = keras.Sequential([
    keras.Sequential([
        layers.Conv2D(8, 3, activation='relu', input_shape=(224, 224, 3)),
        layers.MaxPooling2D(2),
        layers.Conv2D(16, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.Conv2D(32, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.Conv2D(64, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.Conv2D(128, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.Flatten(),
        layers.Dense(1280, activation='relu')
    ]),
    keras.Sequential([
        layers.Dropout(0.2),
        layers.Dense(8, activation='softmax')
    ])
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

# Train the model
epochs = 50
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size
)

print("Train Generator Class Indices:", train_generator.class_indices)
print("Validation Generator Class Indices:", validation_generator.class_indices)

# Save the trained model weights
model.save('/content/drive/MyDrive/AI Model/image_recognition_model.h5')
